{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bangla_speech_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7MwDmQUtMf7"
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN\n",
        "    # tend to be garbage:\n",
        "    #y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA507XNvv0Zh"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF1xaX07wLvp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "082a2f1b-fccc-4cc8-917f-b8381b61eba2"
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMZPJ-U0w6Fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dd912649-9c51-411c-a72d-828bb38906b9"
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20_30_weights.h5\t\t unique_chars_utf.npy  y_20_30.npy\n",
            "bangla_speech_recognition.ipynb  utt_spk_text.tsv      y_len_20_30.npy\n",
            "u_chars_utf.npy\t\t\t x_20_30.npy\t       y_mapped_utf_20_30.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL7OITm5xDea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a513713e-7d3c-40e2-f087-7ad0519f568c"
      },
      "source": [
        "import numpy as np\n",
        "from keras import regularizers\n",
        "x=np.load(\"/content/drive/My Drive/Colab/test_x_0_10.npy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z36YJVKCxNS7"
      },
      "source": [
        "y=np.load(\"/content/drive/My Drive/Colab/test_y_0_10.npy\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uRfRHZGyQTl"
      },
      "source": [
        "y_utf=np.load(\"/content/drive/My Drive/Colab/test_x_mapped0_10.npy\")\n",
        "y_len=np.load(\"/content/drive/My Drive/Colab/test_y_len_0_10.npy\")\n",
        "#y=np.load(\"/content/drive/My Drive/Colab/y_0_10_78utf_spec.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArJn38H90gLq"
      },
      "source": [
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import random_normal\n",
        "from keras.utils.conv_utils import conv_output_length\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.layers import Dense, Activation, Bidirectional, Reshape,Flatten, Lambda, Input,\\\n",
        "    Masking, Convolution1D, BatchNormalization, GRU, Conv1D, RepeatVector, Conv2D\n",
        "from keras.optimizers import SGD, adam\n",
        "from keras.layers import ZeroPadding1D, Convolution1D, ZeroPadding2D, Convolution2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.layers import TimeDistributed, Dropout\n",
        "from keras.layers.merge import add  # , # concatenate BAD FOR COREML\n",
        "from keras.utils.conv_utils import conv_output_length\n",
        "from keras.activations import relu\n",
        "import numpy as np \n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "from keras.models import Model\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "#from pre_processing_v4 import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtih2tQ8zGj_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "111c19a4-7763-4a8d-f989-162e7f6c5848"
      },
      "source": [
        "size=x.shape[0]\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNwshxl6zcy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27efd6a7-d7e0-496d-91a0-af41f5a7e28e"
      },
      "source": [
        "input_length = np.zeros([size, 1])\n",
        "label_length = np.zeros([size, 1])\n",
        "audio_labels = np.ones([size, 30])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "inputs = {'the_input': x,\n",
        "          'the_labels': audio_labels,\n",
        "          'input_length': input_length,\n",
        "          'label_length': label_length,\n",
        "          }\n",
        "\n",
        "\n",
        "outputs = {'ctc': np.zeros([size])}\n",
        "\n",
        "\n",
        "input_length2=np.zeros([size, 1])\n",
        "label_length2=np.zeros([size, 1])\n",
        "\n",
        "for i in range(size):\n",
        "\tinput_length2[i] = 5000\n",
        "\t#label_length2[i]=(i+100)/5\n",
        "\n",
        "label_length2 = y_len\n",
        "print(label_length2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 10 10 ... 10  6  6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPLu_IdWzjcf"
      },
      "source": [
        "x= x.reshape(x.shape[0],5000,1)\n",
        "input_shape=(5000,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSSb6tG7zsnX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9134c865-d287-42b9-e7bc-829c9482474c"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 5000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSZDFNDu0tvC"
      },
      "source": [
        "def selu(x):\n",
        "    # from Keras 2.0.6 - does not exist in 2.0.4\n",
        "    \"\"\"Scaled Exponential Linear Unit. (Klambauer et al., 2017)\n",
        "    # Arguments\n",
        "       x: A tensor or variable to compute the activation function for.\n",
        "    # References\n",
        "       - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n",
        "    \"\"\"\n",
        "    alpha = 1.6732632423543772848170429916717\n",
        "    scale = 1.0507009873554804934193349852946\n",
        "    return scale * K.elu(x, alpha)\n",
        "\n",
        "\n",
        "def clipped_relu(x):\n",
        "    return relu(x, max_value=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JfYKFo-0-iz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7b38a7d-ebc5-4d84-a7cd-1c929110d467"
      },
      "source": [
        "rnn_size=100\n",
        "fc_size=248\n",
        "output_dim=79\n",
        "\n",
        "input_length2=np.zeros([size, 1])\n",
        "label_length2=np.zeros([size, 1])\n",
        "\n",
        "for i in range(size):\n",
        "\tinput_length2[i] = 5000\n",
        "\t#label_length2[i]=(i+100)/5\n",
        "\n",
        "label_length2 = y_len\n",
        "print(label_length2)\n",
        "\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "get_custom_objects().update({\"clipped_relu\": clipped_relu})    \n",
        "K.set_learning_phase(1)\n",
        "\n",
        "input_shape=(5000,1)\n",
        "\n",
        "init = random_normal(stddev=0.046875)\n",
        "\n",
        "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
        "q = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(input_data)\n",
        "conv = ZeroPadding1D(padding=(0, 2048))(q)\n",
        "\n",
        "for l in range(1):\n",
        "\tq = Conv1D(filters=fc_size, name='conv_{}'.format(l+1), kernel_size=11, padding='valid', activation='relu', strides=2)(conv)\n",
        "\n",
        "q = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(q)\n",
        "\n",
        "for l in range(1):\n",
        "\tq = Bidirectional(GRU(rnn_size, name='fc_{}'.format(l + 1), return_sequences=True, activation='relu', kernel_initializer='glorot_uniform'),\n",
        "                      merge_mode='sum')(q)\n",
        "\n",
        "q = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(q)\n",
        "\n",
        "q = TimeDistributed(Dense(fc_size, activation=clipped_relu))(q)\n",
        "y_pred = TimeDistributed(Dense(output_dim, name=\"y_pred\", activation=\"softmax\"))(q)\n",
        "\n",
        "model1=Model(inputs=input_data, outputs=y_pred)\n",
        "\n",
        "labels = Input(name='the_labels',\n",
        "                   shape=[30], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "\n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred,\n",
        "                                                                       labels,\n",
        "                                                                       input_length,\n",
        "                                                                       label_length])\n",
        "\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17 21 13 ... 10  8  8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9anpFLhJgZd"
      },
      "source": [
        "def clipped_relu(x):\n",
        "    return relu(x, max_value=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSD9WNXCI3-W"
      },
      "source": [
        "rnn_size=100\n",
        "fc_size=1048\n",
        "output_dim=79\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "init = random_normal(stddev=0.046875)\n",
        "\n",
        "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
        "#q = Conv1D(64, kernel_size=3, activation='relu', input_shape=(10,22))(input_data)\n",
        "\n",
        "q = Bidirectional(LSTM(rnn_size, return_sequences=True, \n",
        "                                kernel_initializer='he_normal', name='birnn'), merge_mode='sum')(input_data)\n",
        "\n",
        "\n",
        "y_pred = TimeDistributed(Dense(output_dim, name=\"y_pred\", kernel_initializer=init, bias_initializer=init, activation=\"softmax\"))(q)\n",
        "\n",
        "model1=Model(inputs=input_data, outputs=y_pred)\n",
        "\n",
        "labels = Input(name='the_labels', shape=[10], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "\n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred,\n",
        "                                                                       labels,\n",
        "                                                                       input_length,\n",
        "                                                                       label_length])\n",
        "\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "#model.load_weights('short_data_v8.h5')\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='sgd',metrics=['accuracy'])\n",
        "\n",
        "outputs = {'ctc': np.zeros([len(x)])}\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx_r_cUM1ISL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "fb9f1385-e6c1-477d-a8cd-21a04e076fa1"
      },
      "source": [
        "#model.load_weights('/content/drive/My Drive/Colab/0_10_78utf_spec.h5')\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "outputs = {'ctc': np.zeros([len(x)])}\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.001)\n",
        "\n",
        "model.fit([np.array(x), np.array(y_utf), np.array(input_length2), np.array(label_length2)], outputs,epochs=100, callbacks=[reduce_lr],batch_size=200)\n",
        "model.save_weights('/content/drive/My Drive/Colab/0_30_78utf_22.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "55299/55299 [==============================] - 1512s 27ms/step - loss: 63.8914 - acc: 0.0000e+00\n",
            "Epoch 2/100\n",
            "55299/55299 [==============================] - 1493s 27ms/step - loss: 57.6870 - acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            "55299/55299 [==============================] - 1496s 27ms/step - loss: 56.5166 - acc: 0.0000e+00\n",
            "Epoch 4/100\n",
            "55299/55299 [==============================] - 1492s 27ms/step - loss: 55.7958 - acc: 0.0000e+00\n",
            "Epoch 5/100\n",
            "55299/55299 [==============================] - 1496s 27ms/step - loss: 55.4801 - acc: 0.0000e+00\n",
            "Epoch 6/100\n",
            "55299/55299 [==============================] - 1496s 27ms/step - loss: 55.4003 - acc: 0.0000e+00\n",
            "Epoch 7/100\n",
            "55299/55299 [==============================] - 1497s 27ms/step - loss: 55.3719 - acc: 0.0000e+00\n",
            "Epoch 8/100\n",
            "55299/55299 [==============================] - 1496s 27ms/step - loss: 57.2969 - acc: 0.0000e+00\n",
            "Epoch 9/100\n",
            "55299/55299 [==============================] - 1498s 27ms/step - loss: 55.6961 - acc: 0.0000e+00\n",
            "Epoch 10/100\n",
            "55299/55299 [==============================] - 1497s 27ms/step - loss: 55.3740 - acc: 0.0000e+00\n",
            "Epoch 11/100\n",
            "55299/55299 [==============================] - 1497s 27ms/step - loss: 55.2831 - acc: 0.0000e+00\n",
            "Epoch 12/100\n",
            "55299/55299 [==============================] - 1498s 27ms/step - loss: 55.2402 - acc: 0.0000e+00\n",
            "Epoch 13/100\n",
            "55299/55299 [==============================] - 1500s 27ms/step - loss: 55.2060 - acc: 0.0000e+00\n",
            "Epoch 14/100\n",
            "55299/55299 [==============================] - 1511s 27ms/step - loss: 55.1575 - acc: 0.0000e+00\n",
            "Epoch 15/100\n",
            "55299/55299 [==============================] - 1490s 27ms/step - loss: 55.1306 - acc: 0.0000e+00\n",
            "Epoch 16/100\n",
            "55299/55299 [==============================] - 1489s 27ms/step - loss: 55.1058 - acc: 0.0000e+00\n",
            "Epoch 17/100\n",
            "55299/55299 [==============================] - 1485s 27ms/step - loss: 55.2209 - acc: 0.0000e+00\n",
            "Epoch 18/100\n",
            "55299/55299 [==============================] - 1484s 27ms/step - loss: 55.0584 - acc: 0.0000e+00\n",
            "Epoch 19/100\n",
            "55299/55299 [==============================] - 1484s 27ms/step - loss: 55.0480 - acc: 0.0000e+00\n",
            "Epoch 20/100\n",
            "55299/55299 [==============================] - 1517s 27ms/step - loss: 55.0244 - acc: 0.0000e+00\n",
            "Epoch 21/100\n",
            "55299/55299 [==============================] - 1522s 28ms/step - loss: 55.0252 - acc: 0.0000e+00\n",
            "Epoch 22/100\n",
            "55299/55299 [==============================] - 1534s 28ms/step - loss: 55.0249 - acc: 0.0000e+00\n",
            "Epoch 23/100\n",
            "55299/55299 [==============================] - 1525s 28ms/step - loss: 55.0021 - acc: 0.0000e+00\n",
            "Epoch 24/100\n",
            "55299/55299 [==============================] - 1528s 28ms/step - loss: 54.9956 - acc: 0.0000e+00\n",
            "Epoch 25/100\n",
            "55299/55299 [==============================] - 1516s 27ms/step - loss: 54.9986 - acc: 0.0000e+00\n",
            "Epoch 26/100\n",
            "55299/55299 [==============================] - 1518s 27ms/step - loss: 55.0027 - acc: 0.0000e+00\n",
            "Epoch 27/100\n",
            "55299/55299 [==============================] - 1518s 27ms/step - loss: 54.9833 - acc: 0.0000e+00\n",
            "Epoch 28/100\n",
            "55299/55299 [==============================] - 1508s 27ms/step - loss: 54.9940 - acc: 0.0000e+00\n",
            "Epoch 29/100\n",
            "29800/55299 [===============>..............] - ETA: 11:34 - loss: 54.9574 - acc: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofDE6Dm6J8U9"
      },
      "source": [
        "# model.fit([np.array(x), np.array(y_utf), np.array(input_length2), np.array(label_length2)], outputs,epochs=3500, batch_size=200, callbacks=[reduce_lr])\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y24qss2R1-KF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}